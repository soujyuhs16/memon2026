# ä¸­æ–‡è¯„è®ºå®¡æ ¸ç³»ç»Ÿ (Chinese Comment Moderation System)

åŸºäº Transformer çš„ä¸­æ–‡æœ‰æ¯’è¯„è®ºåˆ†ç±»ç³»ç»Ÿï¼Œé¢å‘ ToxiCN æ•°æ®é›†çš„ `toxic` äºŒåˆ†ç±»ä»»åŠ¡ï¼Œé›†æˆè§„åˆ™æ¨¡å—ç”¨äºå¹¿å‘Šå¯¼æµæ£€æµ‹ã€‚

## âš ï¸ é‡è¦å£°æ˜

**æœ¬é¡¹ç›®ä»…ä¾›ç§‘ç ”å’Œå­¦æœ¯ç”¨é€”ï¼Œä¸å¾—ç”¨äºå•†ä¸šç›®çš„ã€‚**

- **æ•°æ®é›†**: ToxiCN 1.0
- **è®¸å¯**: CC BY-NC-ND 4.0 (éå•†ä¸š-ç¦æ­¢æ¼”ç»)
- **å¼•ç”¨**: ACL 2023
- **å†…å®¹è­¦å‘Š**: æ•°æ®é›†åŒ…å«æœ‰æ¯’/æ”»å‡»æ€§å†…å®¹ï¼Œä»…ç”¨äºç§‘ç ”ç›®çš„

### ToxiCN å¼•ç”¨

å¦‚æœæ‚¨ä½¿ç”¨æœ¬ç³»ç»Ÿæˆ– ToxiCN æ•°æ®é›†ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@inproceedings{zhou-etal-2023-toxicn,
    title = "{T}oxic{CN}: A Dataset for Detecting Toxic Content in {C}hinese Conversations",
    author = "Zhou, Hao and others",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics",
    year = "2023"
}
```

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬ç³»ç»Ÿå®ç°äº†ç«¯åˆ°ç«¯çš„ä¸­æ–‡è¯„è®ºå®¡æ ¸æµç¨‹ï¼š

1. **è®­ç»ƒæ¨¡å—** (`src/train.py`): åŸºäº `hfl/chinese-roberta-wwm-ext` å¾®è°ƒäºŒåˆ†ç±»æ¨¡å‹
2. **æ¨ç†æ¨¡å—** (`src/predict.py`): å¯å¤ç”¨çš„é¢„æµ‹å‡½æ•°ï¼Œæ”¯æŒå•æ¡/æ‰¹é‡æ¨ç†
3. **è§„åˆ™æ¨¡å—** (`src/rules.py`): æ­£åˆ™è¡¨è¾¾å¼æ£€æµ‹å¹¿å‘Šå¯¼æµï¼ˆURL/å¾®ä¿¡/QQ/æ‰‹æœºå·ç­‰ï¼‰
4. **FastAPI æœåŠ¡** (`api/main.py`): REST APIï¼Œæ”¯æŒå•æ¡å’Œæ‰¹é‡CSVé¢„æµ‹
5. **Streamlit ç•Œé¢** (`app/app.py`): Web UI ç®¡ç†ç•Œé¢

### ç³»ç»Ÿç‰¹æ€§

- âœ… äºŒåˆ†ç±»ä»»åŠ¡ï¼ˆtoxic æ ‡ç­¾ï¼Œsigmoid å•è¾“å‡ºï¼‰
- âœ… è§„åˆ™èåˆï¼šæ¨¡å‹é¢„æµ‹ + å¹¿å‘Šæ£€æµ‹è§„åˆ™
- âœ… å¯é…ç½®é˜ˆå€¼ï¼ˆé»˜è®¤ 0.5ï¼‰
- âœ… è¾“å‡ºåŒ…å« `model_prob`, `rule_hits`, `rule_score`, `final_prob`, `pred`
- âœ… æ”¯æŒæ‰¹é‡é¢„æµ‹å’ŒCSVæ–‡ä»¶å¤„ç†

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py              # FastAPI æœåŠ¡
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py               # Streamlit ç•Œé¢
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py             # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ predict.py           # æ¨ç†æ¨¡å—
â”‚   â”œâ”€â”€ rules.py             # è§„åˆ™æ£€æµ‹æ¨¡å—
â”‚   â””â”€â”€ data.py              # æ•°æ®åŠ è½½å·¥å…·
â”œâ”€â”€ data/
â”‚   â””â”€â”€ .gitkeep             # æ•°æ®ç›®å½•ï¼ˆCSVæ–‡ä»¶ä¸æäº¤ï¼‰
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ .gitkeep             # è¾“å‡ºç›®å½•ï¼ˆæ¨¡å‹å’Œç»“æœä¸æäº¤ï¼‰
â”œâ”€â”€ requirements.txt         # Python ä¾èµ–
â”œâ”€â”€ .gitignore               # Git å¿½ç•¥è§„åˆ™
â””â”€â”€ README.md                # æœ¬æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®ï¼ˆCondaï¼‰

**åˆ›å»º Conda ç¯å¢ƒ:**

```bash
# åˆ›å»ºæ–°ç¯å¢ƒï¼ˆPython 3.10 æ¨èï¼‰
conda create -n memon python=3.10 -y

# æ¿€æ´»ç¯å¢ƒ
conda activate memon

# å®‰è£… PyTorchï¼ˆæ ¹æ®ä½ çš„ CUDA ç‰ˆæœ¬é€‰æ‹©ï¼‰
# CUDA 11.8 ç¤ºä¾‹:
conda install pytorch pytorch-cuda=11.8 -c pytorch -c nvidia -y

# æˆ–è€… CPU ç‰ˆæœ¬:
# conda install pytorch cpuonly -c pytorch -y

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt
```

**å¿«é€Ÿä¸€é”®å®‰è£…:**

```bash
conda create -n memon python=3.10 -y && \
conda activate memon && \
conda install pytorch pytorch-cuda=11.8 -c pytorch -c nvidia -y && \
pip install -r requirements.txt
```

### 2. å‡†å¤‡æ•°æ®

**ä¸‹è½½ ToxiCN æ•°æ®é›†å¹¶æ”¾ç½®åˆ° `data/` ç›®å½•:**

```bash
# å°† ToxiCN_1.0.csv å¤åˆ¶åˆ° data/ ç›®å½•
cp /path/to/ToxiCN_1.0.csv data/

# éªŒè¯æ–‡ä»¶å­˜åœ¨
ls data/ToxiCN_1.0.csv
```

**æ•°æ®æ ¼å¼è¦æ±‚:**

- CSV æ–‡ä»¶åŒ…å«è‡³å°‘ä¸¤åˆ—: `content` (æ–‡æœ¬) å’Œ `toxic` (æ ‡ç­¾ 0/1)
- æ–‡ä»¶ç¼–ç : UTF-8

### 3. è®­ç»ƒæ¨¡å‹

**åŸºç¡€è®­ç»ƒï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ï¼‰:**

```bash
python src/train.py
```

**è‡ªå®šä¹‰å‚æ•°è®­ç»ƒ:**

```bash
python src/train.py \
  --csv_path data/ToxiCN_1.0.csv \
  --model_name hfl/chinese-roberta-wwm-ext \
  --output_dir outputs \
  --epochs 3 \
  --batch_size 32 \
  --lr 2e-5 \
  --max_length 128 \
  --seed 42 \
  --threshold 0.5
```

**è®­ç»ƒå‚æ•°è¯´æ˜:**

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--csv_path` | ToxiCN æ•°æ®é›†è·¯å¾„ | `data/ToxiCN_1.0.csv` |
| `--model_name` | é¢„è®­ç»ƒæ¨¡å‹åç§° | `hfl/chinese-roberta-wwm-ext` |
| `--output_dir` | è¾“å‡ºç›®å½• | `outputs` |
| `--max_length` | æœ€å¤§åºåˆ—é•¿åº¦ | 128 |
| `--epochs` | è®­ç»ƒè½®æ•° | 3 |
| `--batch_size` | è®­ç»ƒæ‰¹æ¬¡å¤§å° | 32 |
| `--lr` | å­¦ä¹ ç‡ | 2e-5 |
| `--seed` | éšæœºç§å­ | 42 |
| `--threshold` | é¢„æµ‹é˜ˆå€¼ | 0.5 |

**è®­ç»ƒè¾“å‡º:**

è®­ç»ƒå®Œæˆåï¼Œä¼šåœ¨ `outputs/` ç›®å½•ä¸‹ç”Ÿæˆï¼š

```
outputs/
â”œâ”€â”€ model/                    # ä¿å­˜çš„æ¨¡å‹å’Œtokenizer
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â””â”€â”€ tokenizer_config.json
â”œâ”€â”€ metrics_dev.json          # éªŒè¯é›†æŒ‡æ ‡
â”œâ”€â”€ metrics_test.json         # æµ‹è¯•é›†æŒ‡æ ‡
â””â”€â”€ test_predictions.csv      # æµ‹è¯•é›†é¢„æµ‹ç»“æœ
```

### 4. å¯åŠ¨ FastAPI æœåŠ¡

**å¯åŠ¨ API æœåŠ¡å™¨:**

```bash
# æ–¹å¼1: ä½¿ç”¨ uvicornï¼ˆæ¨èç”¨äºå¼€å‘ï¼‰
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000

# æ–¹å¼2: ç›´æ¥è¿è¡Œ
python api/main.py

# æ–¹å¼3: ç”Ÿäº§ç¯å¢ƒï¼ˆå¤šworkerï¼‰
uvicorn api.main:app --host 0.0.0.0 --port 8000 --workers 4
```

**è®¿é—® API æ–‡æ¡£:**

æ‰“å¼€æµè§ˆå™¨è®¿é—®: http://localhost:8000/docs

### 5. å¯åŠ¨ Streamlit ç•Œé¢

**å¯åŠ¨ Web UI:**

```bash
streamlit run app/app.py
```

é»˜è®¤ä¼šåœ¨æµè§ˆå™¨è‡ªåŠ¨æ‰“å¼€: http://localhost:8501

## ğŸ“¡ API ä½¿ç”¨ç¤ºä¾‹

### å•æ¡é¢„æµ‹

**è¯·æ±‚ç¤ºä¾‹ (curl):**

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "è¿™ä¸ªäº§å“å¾ˆå¥½ç”¨ï¼Œæ¨èå¤§å®¶è´­ä¹°",
    "threshold": 0.5
  }'
```

**å“åº”ç¤ºä¾‹:**

```json
{
  "text": "è¿™ä¸ªäº§å“å¾ˆå¥½ç”¨ï¼Œæ¨èå¤§å®¶è´­ä¹°",
  "model_prob": 0.023,
  "rule_hits": [],
  "rule_score": 0.0,
  "final_prob": 0.023,
  "pred": 0,
  "threshold": 0.5
}
```

**å¹¿å‘Šæ£€æµ‹ç¤ºä¾‹:**

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "åŠ å¾®ä¿¡VX123456äº†è§£è¯¦æƒ…ï¼Œä½ä»·æ‰¹å‘",
    "threshold": 0.5
  }'
```

**å“åº”:**

```json
{
  "text": "åŠ å¾®ä¿¡VX123456äº†è§£è¯¦æƒ…ï¼Œä½ä»·æ‰¹å‘",
  "model_prob": 0.156,
  "rule_hits": ["WeChat", "Price"],
  "rule_score": 1.0,
  "final_prob": 1.0,
  "pred": 1,
  "threshold": 0.5
}
```

### æ‰¹é‡é¢„æµ‹

**ä¸Šä¼  CSV æ–‡ä»¶:**

```bash
curl -X POST "http://localhost:8000/batch_predict" \
  -F "file=@test_comments.csv" \
  -F "threshold=0.5" \
  -F "text_column=content" \
  -o predictions.csv
```

**Python ç¤ºä¾‹:**

```python
import requests

# å•æ¡é¢„æµ‹
response = requests.post(
    "http://localhost:8000/predict",
    json={
        "text": "è¿™ä¸ªäº§å“å¾ˆå¥½ç”¨",
        "threshold": 0.5
    }
)
print(response.json())

# æ‰¹é‡é¢„æµ‹
with open('test_comments.csv', 'rb') as f:
    files = {'file': f}
    data = {'threshold': 0.5, 'text_column': 'content'}
    response = requests.post(
        "http://localhost:8000/batch_predict",
        files=files,
        data=data
    )
    
    # ä¿å­˜ç»“æœ
    with open('predictions.csv', 'wb') as out:
        out.write(response.content)
```

## ğŸ¨ Streamlit ç•Œé¢åŠŸèƒ½

### å•æ¡é¢„æµ‹

1. è¾“å…¥è¯„è®ºæ–‡æœ¬
2. è°ƒæ•´åˆ¤å®šé˜ˆå€¼ï¼ˆä¾§è¾¹æ ï¼‰
3. ç‚¹å‡»"é¢„æµ‹"æŒ‰é’®
4. æŸ¥çœ‹ç»“æœï¼š
   - æ¨¡å‹æ¦‚ç‡
   - è§„åˆ™åˆ†æ•°
   - æœ€ç»ˆæ¦‚ç‡
   - åˆ¤å®šç»“æœï¼ˆæœ‰æ¯’/æ­£å¸¸ï¼‰
   - è§„åˆ™å‘½ä¸­åˆ—è¡¨

### æ‰¹é‡é¢„æµ‹

1. ä¸Šä¼  CSV æ–‡ä»¶
2. é€‰æ‹©æ–‡æœ¬åˆ—å
3. ç‚¹å‡»"æ‰¹é‡é¢„æµ‹"
4. æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯å’Œé¢„è§ˆ
5. ä¸‹è½½å®Œæ•´é¢„æµ‹ç»“æœ

## ğŸ§ª è§„åˆ™æ£€æµ‹æ¨¡å—

è§„åˆ™æ¨¡å— (`src/rules.py`) æ£€æµ‹ä»¥ä¸‹å¹¿å‘Šå¯¼æµæ¨¡å¼ï¼š

| è§„åˆ™ç±»å‹ | æ£€æµ‹å†…å®¹ | ç¤ºä¾‹ |
|---------|---------|------|
| URL | ç½‘å€é“¾æ¥ | `http://example.com`, `www.site.com` |
| WeChat | å¾®ä¿¡å·/VX | `å¾®ä¿¡`, `VX123456`, `å¨ä¿¡` |
| QQ | QQå·/ç¾¤ | `QQ:123456789`, `æ‰£æ‰£ç¾¤` |
| Phone | æ‰‹æœºå· | `13812345678` |
| Price | ä»·æ ¼/ä¼˜æƒ  | `ä½ä»·`, `ä¼˜æƒ `, `è¿”ç°`, `ä»…éœ€99å…ƒ` |
| Group | åŠ ç¾¤å¼•å¯¼ | `åŠ ç¾¤`, `è¿›ç¾¤`, `ç¾¤å·` |
| Scam | åˆ·å•/å…¼èŒ | `åˆ·å•`, `å…¼èŒ`, `æ—¥èµšåƒå…ƒ` |
| Contact | è”ç³»å¼•å¯¼ | `ç§ä¿¡æˆ‘`, `è¯¦æƒ…å’¨è¯¢` |

**èåˆç­–ç•¥:**

- é»˜è®¤: `final_prob = max(model_prob, rule_score)`
- å¯é…ç½®è§„åˆ™è¦†ç›– (`RULE_OVERRIDE=True`): è§„åˆ™å‘½ä¸­ç›´æ¥åˆ¤å®šä¸ºæœ‰æ¯’

**è§„åˆ™åˆ†æ•°è®¡ç®—:**

- å‘½ä¸­ 0 ä¸ªè§„åˆ™: `score = 0.0`
- å‘½ä¸­ 1 ä¸ªè§„åˆ™: `score = 0.6`
- å‘½ä¸­ 2+ ä¸ªè§„åˆ™: `score = 1.0`

## ğŸ” æœ¬åœ°å¿«é€Ÿæ¨ç†éªŒè¯

åœ¨è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¿«é€ŸéªŒè¯æ¨ç†åŠŸèƒ½ï¼š

### Python æ¥å£éªŒè¯

```python
# å¯¼å…¥æ¨ç†æ¥å£
from src.predict import load_predictor

# åŠ è½½æ¨¡å‹
predictor = load_predictor('outputs/model')

# å•æ¡é¢„æµ‹
result = predictor.predict_one('åŠ vxé¢†èµ„æ–™ï¼Œä½ä»·ä»£åˆ·', threshold=0.5)
print(result)
# è¾“å‡ºç¤ºä¾‹:
# {
#   'text': 'åŠ vxé¢†èµ„æ–™ï¼Œä½ä»·ä»£åˆ·',
#   'model_prob': 0.856,
#   'rule_hits': ['WeChat', 'Price'],
#   'rule_score': 1.0,
#   'final_prob': 1.0,
#   'pred': 1,
#   'threshold': 0.5
# }

# æ‰¹é‡é¢„æµ‹
texts = ['è¿™ä¸ªäº§å“å¾ˆå¥½ç”¨', 'åŠ å¾®ä¿¡é¢†ä¼˜æƒ ', 'è¯·ç§ä¿¡æˆ‘']
results = predictor.predict_batch(texts, threshold=0.5)
for r in results:
    print(f"{r['text']}: pred={r['pred']}, final_prob={r['final_prob']:.3f}")
```

### å‘½ä»¤è¡Œå¿«é€Ÿæµ‹è¯•

```bash
# å•æ¡é¢„æµ‹æµ‹è¯•
python -c "from src.predict import load_predictor; p=load_predictor('outputs/model'); print(p.predict_one('åŠ vxé¢†èµ„æ–™ï¼Œä½ä»·ä»£åˆ·', threshold=0.5))"

# æ‰¹é‡é¢„æµ‹æµ‹è¯•
python -c "from src.predict import load_predictor; p=load_predictor('outputs/model'); texts=['æ­£å¸¸è¯„è®º', 'åŠ å¾®ä¿¡VX123']; results=p.predict_batch(texts); [print(r) for r in results]"
```

### æ¨ç†æ¥å£è¯´æ˜

#### `load_predictor(model_dir, device=None)`

åŠ è½½é¢„æµ‹å™¨å®ä¾‹ã€‚

- **å‚æ•°**:
  - `model_dir` (str): æ¨¡å‹ç›®å½•è·¯å¾„ï¼ˆå¦‚ `'outputs/model'`ï¼‰
  - `device` (str, optional): è®¾å¤‡é€‰æ‹©ï¼ˆ`'cuda'`ã€`'cpu'` æˆ– `None` è‡ªåŠ¨æ£€æµ‹ï¼‰
- **è¿”å›**: `Predictor` å®ä¾‹

#### `predictor.predict_one(text, threshold=0.5, use_rules=True, rule_override=False)`

å•æ¡æ–‡æœ¬é¢„æµ‹ã€‚

- **å‚æ•°**:
  - `text` (str): è¾“å…¥æ–‡æœ¬
  - `threshold` (float): åˆ¤å®šé˜ˆå€¼ï¼Œé»˜è®¤ 0.5
  - `use_rules` (bool): æ˜¯å¦ä½¿ç”¨è§„åˆ™èåˆï¼Œé»˜è®¤ True
  - `rule_override` (bool): è§„åˆ™å‘½ä¸­æ—¶æ˜¯å¦ç›´æ¥åˆ¤å®šä¸ºæœ‰æ¯’ï¼Œé»˜è®¤ False
- **è¿”å›**: å­—å…¸ï¼ŒåŒ…å« `model_prob`ã€`rule_hits`ã€`rule_score`ã€`final_prob`ã€`pred`ã€`threshold`

#### `predictor.predict_batch(texts, threshold=0.5, use_rules=True, rule_override=False, batch_size=32)`

æ‰¹é‡æ–‡æœ¬é¢„æµ‹ã€‚

- **å‚æ•°**:
  - `texts` (List[str]): æ–‡æœ¬åˆ—è¡¨
  - `threshold` (float): åˆ¤å®šé˜ˆå€¼ï¼Œé»˜è®¤ 0.5
  - `use_rules` (bool): æ˜¯å¦ä½¿ç”¨è§„åˆ™èåˆï¼Œé»˜è®¤ True
  - `rule_override` (bool): è§„åˆ™å‘½ä¸­æ—¶æ˜¯å¦ç›´æ¥åˆ¤å®šä¸ºæœ‰æ¯’ï¼Œé»˜è®¤ False
  - `batch_size` (int): æ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤ 32
- **è¿”å›**: å­—å…¸åˆ—è¡¨

### å‘åå…¼å®¹

ä¸ºä¿æŒå…¼å®¹æ€§ï¼Œä»¥ä¸‹æ—§æ¥å£ä»ç„¶å¯ç”¨ï¼š

```python
# æ—§æ¥å£ï¼ˆä»å¯ç”¨ï¼‰
from src.predict import load_model, ToxicClassifier

classifier = load_model('outputs/model')
result = classifier.predict_single('æ–‡æœ¬')  # æ—§æ–¹æ³•å

# æ–°æ¥å£ï¼ˆæ¨èï¼‰
from src.predict import load_predictor, Predictor

predictor = load_predictor('outputs/model')
result = predictor.predict_one('æ–‡æœ¬')  # æ–°æ–¹æ³•å
```

## ğŸ“Š è¾“å‡ºæ ¼å¼

### æµ‹è¯•é›†é¢„æµ‹æ–‡ä»¶ (`outputs/test_predictions.csv`)

| åˆ—å | è¯´æ˜ |
|------|------|
| `content` | åŸå§‹æ–‡æœ¬ |
| `label` | çœŸå®æ ‡ç­¾ (0/1) |
| `model_prob` | æ¨¡å‹é¢„æµ‹æ¦‚ç‡ |
| `rule_score` | è§„åˆ™å¾—åˆ† |
| `final_prob` | èåˆåæœ€ç»ˆæ¦‚ç‡ |
| `pred` | é¢„æµ‹æ ‡ç­¾ (0/1) |
| `rule_hits` | å‘½ä¸­çš„è§„åˆ™åˆ—è¡¨ (é€—å·åˆ†éš”) |

## ğŸ› ï¸ å¼€å‘å’Œè°ƒè¯•

### æµ‹è¯•å„æ¨¡å—

```bash
# æµ‹è¯•è§„åˆ™æ¨¡å—
python src/rules.py

# æµ‹è¯•æ•°æ®åŠ è½½
python src/data.py

# æµ‹è¯•é¢„æµ‹æ¨¡å—ï¼ˆéœ€è¦å…ˆè®­ç»ƒæ¨¡å‹ï¼‰
python src/predict.py
```

### å¸¸è§é—®é¢˜

**Q: æ¨¡å‹ä¸‹è½½æ…¢æˆ–å¤±è´¥ï¼Ÿ**

A: è®¾ç½® Hugging Face é•œåƒæºï¼š

```bash
export HF_ENDPOINT=https://hf-mirror.com
```

æˆ–åœ¨ä»£ç ä¸­è®¾ç½®ä»£ç†ã€‚

**Q: CUDA å†…å­˜ä¸è¶³ï¼Ÿ**

A: å‡å° `batch_size` æˆ– `max_length`ï¼š

```bash
python src/train.py --batch_size 16 --max_length 64
```

**Q: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ï¼Ÿ**

A: ç¡®ä¿å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆæ¨¡å‹ï¼š

```bash
python src/train.py
ls outputs/model/  # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
```

**Q: TrainingArguments å‚æ•°é”™è¯¯ (evaluation_strategy vs eval_strategy)ï¼Ÿ**

A: æœ¬ç³»ç»Ÿå·²å†…ç½®å…¼å®¹é€»è¾‘ï¼Œæ”¯æŒ `transformers` æ–°æ—§ç‰ˆæœ¬ï¼š
- **æ—§ç‰ˆæœ¬** (< 4.19.0): ä½¿ç”¨ `evaluation_strategy` å‚æ•°
- **æ–°ç‰ˆæœ¬** (>= 4.19.0): ä½¿ç”¨ `eval_strategy` å‚æ•°

å¦‚æœä»é‡åˆ°é—®é¢˜ï¼Œå»ºè®®å‡çº§ transformersï¼š

```bash
pip install --upgrade transformers
```

ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å½“å‰ç‰ˆæœ¬å¹¶ä½¿ç”¨æ­£ç¡®çš„å‚æ•°åï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®ã€‚

**Q: è®­ç»ƒæ—¶å‡ºç° `RuntimeError: Found dtype Long but expected Float` é”™è¯¯ï¼Ÿ**

A: è¿™æ˜¯å› ä¸ºä½¿ç”¨ `num_labels=1` é…ç½®æ—¶ï¼Œæ¨¡å‹å†…éƒ¨ä½¿ç”¨ `BCEWithLogitsLoss`ï¼Œè¦æ±‚æ ‡ç­¾ä¸º float ç±»å‹ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼ˆå·²åœ¨æœ€æ–°ç‰ˆæœ¬ä¸­ä¿®å¤ï¼‰ï¼š
- æ ‡ç­¾åˆ—å·²è‡ªåŠ¨è½¬æ¢ä¸º float32 ç±»å‹
- æ ‡ç­¾åˆ—åç»Ÿä¸€ä¸º `labels`ï¼ˆè€Œé `label`ï¼‰
- è®­ç»ƒè„šæœ¬ä¼šåœ¨ tokenization åæ‰“å°æ ‡ç­¾ dtype è¿›è¡Œæ£€æŸ¥

å¦‚æœä»é‡åˆ°æ­¤é—®é¢˜ï¼Œè¯·ç¡®ä¿ï¼š
1. ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„ä»£ç 
2. æ£€æŸ¥æ•°æ®é›†ä¸­çš„æ ‡ç­¾åˆ—æ˜¯å¦ä¸ºæ•°å€¼ç±»å‹ï¼ˆ0/1ï¼‰
3. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—ä¸­çš„ "[Sanity Check]" éƒ¨åˆ†ï¼Œç¡®è®¤ labels dtype ä¸º float32

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

è®­ç»ƒå®Œæˆåï¼ŒæŸ¥çœ‹è¯„ä¼°æŒ‡æ ‡ï¼š

```bash
# éªŒè¯é›†æŒ‡æ ‡
cat outputs/metrics_dev.json

# æµ‹è¯•é›†æŒ‡æ ‡
cat outputs/metrics_test.json
```

æŒ‡æ ‡åŒ…æ‹¬ï¼š
- Accuracy (å‡†ç¡®ç‡)
- Precision (ç²¾ç¡®ç‡)
- Recall (å¬å›ç‡)
- F1 Score (F1åˆ†æ•°)
- AUC (ROCæ›²çº¿ä¸‹é¢ç§¯)

## ğŸ”’ å®‰å…¨å’Œéšç§

- âŒ æ•°æ®æ–‡ä»¶ (`data/*.csv`) **ä¸ä¼š**æäº¤åˆ° Git ä»“åº“
- âŒ æ¨¡å‹æƒé‡ (`outputs/`) **ä¸ä¼š**æäº¤åˆ° Git ä»“åº“
- âœ… æ‰€æœ‰æ•æ„Ÿæ–‡ä»¶å·²åœ¨ `.gitignore` ä¸­é…ç½®
- âš ï¸ è¯·å‹¿å°† API æš´éœ²åˆ°å…¬ç½‘ï¼Œä»…ç”¨äºæœ¬åœ°/å†…ç½‘æµ‹è¯•

## ğŸ“ è®¸å¯å’Œå¼•ç”¨

### æ•°æ®é›†è®¸å¯

ToxiCN æ•°æ®é›†é‡‡ç”¨ **CC BY-NC-ND 4.0** è®¸å¯ï¼š
- âœ… å…è®¸ç§‘ç ”å’Œå­¦æœ¯ä½¿ç”¨
- âŒ ç¦æ­¢å•†ä¸šä½¿ç”¨
- âŒ ç¦æ­¢æ¼”ç»ä¿®æ”¹ï¼ˆä»…å¯å¤åˆ¶å’Œåˆ†å‘ï¼‰

### ç³»ç»Ÿè®¸å¯

æœ¬ç³»ç»Ÿä»£ç å¼€æºï¼Œä¾›å­¦ä¹ å’Œç§‘ç ”ä½¿ç”¨ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·é€šè¿‡ GitHub Issues è”ç³»ã€‚

---

**æœ€åæ›´æ–°**: 2026-01-14