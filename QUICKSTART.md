# å¿«é€Ÿå¼€å§‹æŒ‡å— (Quick Start Guide)

æœ¬æŒ‡å—å¸®åŠ©ä½ åœ¨ 5 åˆ†é’Ÿå†…å¯åŠ¨ä¸­æ–‡è¯„è®ºå®¡æ ¸ç³»ç»Ÿã€‚

## ğŸš€ 5 åˆ†é’Ÿå¿«é€Ÿå¯åŠ¨

### æ­¥éª¤ 1: å…‹éš†ä»“åº“

```bash
git clone https://github.com/soujyuhs16/memon2026.git
cd memon2026
```

### æ­¥éª¤ 2: åˆ›å»ºç¯å¢ƒå¹¶å®‰è£…ä¾èµ–

**ä½¿ç”¨ Conda (æ¨è):**

```bash
# åˆ›å»ºç¯å¢ƒ
conda create -n memon python=3.10 -y

# æ¿€æ´»ç¯å¢ƒ
conda activate memon

# å®‰è£… PyTorch (GPUç‰ˆæœ¬)
conda install pytorch pytorch-cuda=11.8 -c pytorch -c nvidia -y

# æˆ–è€… CPU ç‰ˆæœ¬
# conda install pytorch cpuonly -c pytorch -y

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt
```

**ä½¿ç”¨ pip:**

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
pip install torch  # æˆ–è®¿é—® pytorch.org é€‰æ‹©åˆé€‚ç‰ˆæœ¬
pip install -r requirements.txt
```

### æ­¥éª¤ 3: å‡†å¤‡æ•°æ®

```bash
# å°† ToxiCN_1.0.csv å¤åˆ¶åˆ° data/ ç›®å½•
cp /path/to/ToxiCN_1.0.csv data/

# éªŒè¯æ–‡ä»¶
head -5 data/ToxiCN_1.0.csv
```

**æ•°æ®æ ¼å¼ç¤ºä¾‹:**
```csv
content,toxic
è¿™ä¸ªäº§å“å¾ˆå¥½ç”¨,0
ä½ ä¸ªå‚»X,1
æœåŠ¡æ€åº¦å¾ˆå¥½,0
```

### æ­¥éª¤ 4: è®­ç»ƒæ¨¡å‹

```bash
# å¿«é€Ÿè®­ç»ƒï¼ˆå°æ•°æ®é›†æˆ–æµ‹è¯•ï¼‰
python src/train.py --epochs 1 --batch_size 16

# å®Œæ•´è®­ç»ƒï¼ˆé»˜è®¤å‚æ•°ï¼‰
python src/train.py

# è‡ªå®šä¹‰è®­ç»ƒ
python src/train.py \
  --epochs 3 \
  --batch_size 32 \
  --lr 2e-5 \
  --max_length 128
```

**è®­ç»ƒæ—¶é—´ä¼°ç®—:**
- CPU: 30-60 åˆ†é’Ÿ (å–å†³äºæ•°æ®é‡)
- GPU (Tesla T4): 5-10 åˆ†é’Ÿ

**è®­ç»ƒå®Œæˆåæ£€æŸ¥è¾“å‡º:**
```bash
ls outputs/
# åº”è¯¥çœ‹åˆ°: model/, metrics_dev.json, metrics_test.json, test_predictions.csv
```

### æ­¥éª¤ 5: å¯åŠ¨æœåŠ¡

**æ–¹å¼ A: å¯åŠ¨ FastAPI æœåŠ¡**

```bash
# å¯åŠ¨ API (å¼€å‘æ¨¡å¼)
uvicorn api.main:app --reload

# æˆ–ç”Ÿäº§æ¨¡å¼
uvicorn api.main:app --host 0.0.0.0 --port 8000 --workers 4
```

è®¿é—® API æ–‡æ¡£: http://localhost:8000/docs

**æµ‹è¯• API:**
```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# å•æ¡é¢„æµ‹
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "è¿™ä¸ªäº§å“å¾ˆå¥½ç”¨"}'
```

**æ–¹å¼ B: å¯åŠ¨ Streamlit UI**

```bash
# å¯åŠ¨ Web UI
streamlit run app/app.py
```

è®¿é—®ç•Œé¢: http://localhost:8501

### æ­¥éª¤ 6: å¼€å§‹ä½¿ç”¨

**å•æ¡é¢„æµ‹ (Python):**

```python
from src.predict import load_model

# åŠ è½½æ¨¡å‹
classifier = load_model('outputs/model')

# é¢„æµ‹
result = classifier.predict_single(
    "è¿™ä¸ªäº§å“å¾ˆå¥½ç”¨ï¼Œæ¨èå¤§å®¶è´­ä¹°",
    threshold=0.5
)

print(f"æ–‡æœ¬: {result['text']}")
print(f"é¢„æµ‹: {'æœ‰æ¯’' if result['pred'] == 1 else 'æ­£å¸¸'}")
print(f"æ¦‚ç‡: {result['final_prob']:.3f}")
print(f"è§„åˆ™: {result['rule_hits']}")
```

**æ‰¹é‡é¢„æµ‹ (CSV):**

```python
import pandas as pd
from src.predict import load_model

# åŠ è½½æ¨¡å‹
classifier = load_model('outputs/model')

# è¯»å–CSV
df = pd.read_csv('test_comments.csv')

# æ‰¹é‡é¢„æµ‹
texts = df['content'].tolist()
results = classifier.predict_batch(texts, threshold=0.5)

# ä¿å­˜ç»“æœ
result_df = pd.DataFrame(results)
result_df.to_csv('predictions.csv', index=False)
```

## ğŸ§ª æµ‹è¯•ç³»ç»Ÿ

è¿è¡Œé›†æˆæµ‹è¯•:

```bash
./test_integration.sh
```

æµ‹è¯•è§„åˆ™æ¨¡å—:

```bash
python src/rules.py
```

## ğŸ“– æ›´å¤šä¿¡æ¯

- **å®Œæ•´æ–‡æ¡£**: æŸ¥çœ‹ [README.md](README.md)
- **API ç¤ºä¾‹**: æŸ¥çœ‹ [examples.py](examples.py)
- **å¼€å‘æŒ‡å—**: æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md)
- **æ¶æ„æ–‡æ¡£**: æŸ¥çœ‹ [ARCHITECTURE.md](ARCHITECTURE.md)

## ğŸ› å¸¸è§é—®é¢˜

### Q1: æ¨¡å‹ä¸‹è½½æ…¢æˆ–å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨å›½å†…é•œåƒ

```bash
export HF_ENDPOINT=https://hf-mirror.com
python src/train.py
```

### Q2: CUDA out of memory

**è§£å†³æ–¹æ¡ˆ**: å‡å°æ‰¹æ¬¡å¤§å°

```bash
python src/train.py --batch_size 8 --max_length 64
```

### Q3: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶

**è§£å†³æ–¹æ¡ˆ**: ç¡®ä¿å…ˆè¿è¡Œè®­ç»ƒ

```bash
# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
ls outputs/model/

# å¦‚æœä¸å­˜åœ¨ï¼Œé‡æ–°è®­ç»ƒ
python src/train.py
```

### Q4: API æ— æ³•å¯åŠ¨

**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥ä¾èµ–å’Œæ¨¡å‹

```bash
# æ£€æŸ¥ä¾èµ–
pip list | grep fastapi

# æ£€æŸ¥æ¨¡å‹
ls outputs/model/

# é‡æ–°å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### Q5: Streamlit å¯åŠ¨æ…¢

**è§£å†³æ–¹æ¡ˆ**: æ­£å¸¸ç°è±¡ï¼Œé¦–æ¬¡åŠ è½½æ¨¡å‹éœ€è¦æ—¶é—´

```bash
# æŸ¥çœ‹æ—¥å¿—
streamlit run app/app.py --server.runOnSave false
```

## ğŸ¯ ä¸‹ä¸€æ­¥

1. **è°ƒæ•´é˜ˆå€¼**: æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´åˆ¤å®šé˜ˆå€¼
2. **ä¼˜åŒ–è§„åˆ™**: åœ¨ `src/rules.py` ä¸­æ·»åŠ è‡ªå®šä¹‰è§„åˆ™
3. **æ€§èƒ½ä¼˜åŒ–**: ä½¿ç”¨ GPU åŠ é€Ÿæ¨ç†
4. **éƒ¨ç½²ç”Ÿäº§**: ä½¿ç”¨ Docker å®¹å™¨åŒ–éƒ¨ç½²

## ğŸ“ è·å–å¸®åŠ©

- **GitHub Issues**: æäº¤é—®é¢˜å’Œå»ºè®®
- **æ–‡æ¡£**: æŸ¥çœ‹å®Œæ•´æ–‡æ¡£
- **ç¤¾åŒº**: åŠ å…¥è®¨è®º

---

**ç¥ä½¿ç”¨æ„‰å¿«! ğŸ‰**
